### Baselines
One popular time-domain network, i.e. [FaSNet-TAC](https://arxiv.org/abs/1910.14104), and one recently proposed frequency-domain network, i.e. [SpatialNet](https://arxiv.org/abs/2307.16516), are used for benchmarking the speech enhancement performance of the proposed dataset.


| Code | Description |
| --- | --- |
| `models/arch/SpatialNet.py` | The network implementation of SpatialNet. Configs: `configs/SpatialNetTiny.yaml` |
| `data_loaders/baseline_realistic_audio.py` | The reference dataloader implementation. Configs: `configs/datasets/baseline_realistic_audio_16k.yaml` |
| `SharedTrainer.py` | The pytorch-lightning Trainer implementation for SpatialNet.|
| `FaSNet_TAC.py` | The pytorch-lightning Trainer implementation for FaSNet-TAC. Configs: `configs/FaSNet_TAC.yaml` |



### ASR Evaluation
The ASR performances are evaluated by an established ASR model trained by over 10,000 hours of Mandarin dataset, [WenetSpeech](https://arxiv.org/abs/2110.03370) using [ESPNet toolkit](https://github.com/espnet/espnet).
| Code | Description |
| --- | --- |
| `asr_evaluate/0_inference.py` | Use the ESPnet toolkit and the established ASR model for ASR inference on enhanced speech. |
| `asr_evaluate/1_convert_json_to_trn.py` | Convert '*.json' file generated by `asr_evaluate/0_inference.py` to '*.trn'. |
| `asr_evaluate/2_filter_trn_by_scene.py` | Filter the reference transcript file in the RealMAN dataset to each test scene.|
| `asr_evaluate/3_calculate_cer.py` | Calculate CER using sclite given the path of enhanced trn and reference trn.|
| `asr_evaluate/4_summariza_results` | Summarize CER results in 'summary.md'.|


### Special Thanks
- [yluo42/TAC](https://github.com/yluo42/TAC) for the open-source implementation of FaSNet-TAC.

### Baselines
One popular time-domain network, i.e. [FaSNet-TAC](https://arxiv.org/abs/1910.14104), and one recently proposed frequency-domain network, i.e. [SpatialNet](https://arxiv.org/abs/2307.16516), are used for benchmarking the speech enhancement performance of the proposed dataset.


| Code | Description |
| --- | --- |
| `models/arch/SpatialNet.py` | The network implementation of SpatialNet. Configs: `configs/SpatialNetTiny.yaml` |
| `data_loaders/realman_enh_dataset.py` | The reference dataloader implementation. Configs for baseline: `configs/datasets/realman_enh_baseline_16k.yaml` and configs for microphone-array generalization: `configs/datasets/realman_enh_generalization_16k.yaml` |
| `SharedTrainer.py` | The pytorch-lightning Trainer implementation for SpatialNet.|
| `FaSNet_TAC.py` | The pytorch-lightning Trainer implementation for FaSNet-TAC. Configs: `configs/FaSNet_TAC.yaml` |

#### Usage
* Baseline
  
  For train,
  
  ```
  # enter the corresponding files
  cd baselines/SE/
  
  # commands for FaSNet-TAC
  python -m models.FaSNet_TAC fit --config=configs/fasnet.yaml  --config configs/datasets/realman_enh_baseline_16kHz.yaml  --trainer.devices=0,1, --data.batch_size=[4,1]
  
  # commands for Spatialnet
  python -m models.SharedTrainer fit --config configs/SpatialNetTiny.yaml  --config configs/datasets/realman_enh_baseline_16kHz.yaml  --trainer.devices=0,1  --data.init_args.batch_size=[4,8] --model.compile=true --trainer.precision=16-mixed
  ```

  For test,
  ```
  # commands for FaSNet-TAC
  python -m models.FaSNet_TAC test --config=dir_to_exp/config.yaml --trainer.devices=X,X, --ckpt_path=dir_to_exp/xxx.ckpt
  
  # commands for Spatialnet
  python -m models.SharedTrainer test --config=dir_to_exp/config.yaml --trainer.devices=X,X, --ckpt_path=dir_to_exp/xxx.ckpt
  ```

* Microphone-array generalization
  
  To explore the microphone-array generalization, we also provide the code for organizing the varaible-array data for train. (More details could be found in the function *select_microphone_array_for_enh* in data_loaders/realman_enh_dataset.py)
  
  Take the FaSNet-TAC as example, for train,
  
  ```
  python -m models.FaSNet_TAC fit --config=configs/fasnet.yaml  --config configs/datasets/realman_enh_generalization_16kHz.yaml  --trainer.devices=0,1, --data.batch_size=[1,1] --trainer.accumulate_grad_batches=8
  ```

  For test,
  ```
  python -m models.FaSNet_TAC test --config=dir_to_exp/config.yaml --trainer.devices=X,X, --ckpt_path=dir_to_exp/xxx.ckpt
  ```


### ASR Evaluation
The ASR performances are evaluated by an established ASR model trained by over 10,000 hours of Mandarin dataset, [WenetSpeech](https://arxiv.org/abs/2110.03370) using [ESPNet toolkit](https://github.com/espnet/espnet).
| Code | Description |
| --- | --- |
| `asr_evaluate/0_inference.py` | Use the ESPnet toolkit and the established ASR model for ASR inference on enhanced speech. |
| `asr_evaluate/1_convert_json_to_trn.py` | Convert '*.json' file generated by `asr_evaluate/0_inference.py` to '*.trn'. |
| `asr_evaluate/2_filter_trn_by_scene.py` | Filter the reference transcript file in the RealMAN dataset to each test scene.|
| `asr_evaluate/3_calculate_cer.py` | Calculate CER using sclite given the path of enhanced trn and reference trn.|
| `asr_evaluate/4_summariza_results` | Summarize CER results in 'summary.md'.|


### Special Thanks
- [yluo42/TAC](https://github.com/yluo42/TAC) for the open-source implementation of FaSNet-TAC.

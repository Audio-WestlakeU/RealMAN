##############################################################################################################
# Note: there are datasets relaying on these functions.
# Changing the implementations might change the data generated by these datasets.
#
# Copyright: Changsheng Quan @ Audio Lab of Westlake University
##############################################################################################################
"""
mid:
  ---
-------
headtail:
------
    ----
startend:
---    start/end   ---
------          ------
full:
---------
---------
hms: headtail, mid or startend
fhms: full, headtail, mid or startend
"""

from typing import *

import numpy as np
from numpy import ndarray
from numpy.random import Generator
from scipy.signal import fftconvolve

OVLPS = ['mid', 'headtail', 'startend', 'full', 'hms', 'fhms']


def sample_an_overlap(ovlp_type: str, num_spk: int, rng: Generator) -> str:
    assert ovlp_type in OVLPS, ovlp_type
    assert num_spk in [1, 2], num_spk

    if num_spk == 1:
        ovlp_type = 'full'
    elif ovlp_type == 'fhms':
        types = ['full', 'headtail', 'mid', 'startend']
        which_type = rng.integers(low=0, high=len(types))
        ovlp_type = types[which_type]
    elif ovlp_type == 'hms':
        types = ['headtail', 'mid', 'startend']
        which_type = rng.integers(low=0, high=len(types))
        ovlp_type = types[which_type]
    else:
        assert ovlp_type in ['full', 'headtail', 'mid', 'startend'], ovlp_type

    if ovlp_type == 'startend':
        types = ['start', 'end']
        which_type = rng.integers(low=0, high=len(types))
        ovlp_type = types[which_type]
    else:
        ovlp_type = ovlp_type

    return ovlp_type


def sample_ovlp_ratio_and_cal_length(ovlp_type: str, ratio_range: Tuple[float, float], target_len: Optional[int], lens: List[int], rng: Generator) -> Tuple[float, List[int], int]:
    """sample one overlap ratio and calculate the needed length for each wav

    Returns:
        Tuple[float, List[int]]: ovlp_ratio, needed length 
    """
    for rr in ratio_range:
        assert rr >= 0 and rr <= 1, rr
    assert ratio_range[0] <= ratio_range[1], ratio_range

    if target_len == None:
        mix_frames = max(lens)
        if ovlp_type == 'full':
            ovlp_ratio = 1
        elif ovlp_type == 'headtail':
            low = ratio_range[0]
            high = np.min(lens) / np.max(lens)
            if low > high:
                ovlp_ratio = high
            else:
                ovlp_ratio = rng.uniform(low=low, high=high)
            mix_frames = round((np.min(lens) + np.max(lens)) / (1 + ovlp_ratio))
        elif ovlp_type == 'mid':
            ovlp_ratio = np.min(lens) / np.max(lens)
        else:
            assert ovlp_type in ['start', 'end'], ovlp_type
            ovlp_ratio = np.min(lens) / np.max(lens)
    else:
        mix_frames = target_len
        ovlp_ratio = rng.uniform(low=ratio_range[0], high=ratio_range[1])
        if ovlp_type == 'full':
            lens = [mix_frames] * len(lens)
            ovlp_ratio = 1
        elif ovlp_type == 'headtail':
            lens = [int(mix_frames * (0.5 + ovlp_ratio / 2))] * len(lens)
        else:
            assert ovlp_type in ['mid', 'start', 'end'], ovlp_type
            max_idx = lens.index(max(lens))
            min_idx = lens.index(min(lens))
            if max_idx == min_idx:
                max_idx = [1, 0][max_idx]
            lens[max_idx] = mix_frames
            lens[min_idx] = int(mix_frames * ovlp_ratio)
    return ovlp_ratio, lens, mix_frames


def pad_or_cut(wavs: List[ndarray], lens: List[int], rng: Generator) -> List[ndarray]:
    """repeat signals if they are shorter than the length needed, then cut them to needed
    """
    for i, wav in enumerate(wavs):
        # repeat
        while len(wav) < lens[i]:
            wav = np.concatenate([wav, wav])
        # cut to needed length
        if len(wav) > lens[i]:
            start = rng.integers(low=0, high=len(wav) - lens[i] + 1)
            wav = wav[start:start + lens[i]]
        wavs[i] = wav
    return wavs


def convolve(wav: ndarray, rir: ndarray, rir_target: ndarray, ref_channel: Optional[int] = 0, align: bool = True) -> Tuple[ndarray, ndarray]:
    assert wav.ndim == 1, wav.shape
    assert rir.ndim == 2 and rir_target.ndim == 2, (rir.shape, rir_target.shape)

    rvbt = fftconvolve(wav[np.newaxis, :], rir, mode='full', axes=-1)
    target = rvbt if rir is rir_target else fftconvolve(wav[np.newaxis, :], rir_target, mode='full', axes=-1)
    if align:
        # Note: don't take the dry clean source as target if the ref_channel is not correct
        rir = rir[ref_channel, ...]
        delay = np.argmax(rir)
        rvbt = rvbt[:, delay:delay + wav.shape[-1]]
        target = target[:, delay:delay + wav.shape[-1]]
    return rvbt, target

def convolve_v2(wav: ndarray, rir: ndarray, rir_target: ndarray, ref_channel: Optional[int] = 0, align: bool = True) -> Tuple[ndarray, ndarray]:
    assert wav.ndim == 1, wav.shape
    assert rir.ndim == 2 and rir_target.ndim == 2, (rir.shape, rir_target.shape)

    rvbt = fftconvolve(wav[np.newaxis, :], rir, mode='full', axes=-1)
    target = rvbt if rir is rir_target else fftconvolve(wav[np.newaxis, :], rir_target, mode='full', axes=-1)
    if align:
        # Note: don't take the dry clean source as target if the ref_channel is not correct
        rir_align = rir_target[ref_channel, ...] # use rir_target rather than rir
        delay = np.argmax(rir_align)
        rvbt = rvbt[:, delay:delay + wav.shape[-1]]
        target = target[:, delay:delay + wav.shape[-1]]
    return rvbt, target


def convolve_traj(wav: np.ndarray, traj_rirs: np.ndarray, traj_rirs_tar: np.ndarray, samples_per_rir: Union[np.ndarray, int], ref_channel: Optional[int] = 0, align: bool = True) -> np.ndarray:
    """Convolve wav by using a set of trajectory rirs (Note: the generated audio signal using this method has click noise)

    Args:
        wav: shape [time]
        traj_rirs: shape [num_rirs, num_mics, num_samples]
        traj_rirs_tar: shape [num_rirs, num_mics, num_samples]
        samples_per_rir: the number of samples in wav for each trajectory rir
        ref_channel: reference channel. Defaults to 0.
        align: Defaults to True.

    Returns:
        np.ndarray: [num_mics, time]
    """
    assert wav.ndim == 1, "not implemented"
    wav_samps = wav.shape[0]
    if isinstance(samples_per_rir, np.ndarray):
        assert samples_per_rir.ndim == 1
        assert samples_per_rir.sum() == wav.shape[-1], "the number of samples specified in samples_per_rir should match that of the wav"
    else:
        if wav_samps % samples_per_rir == 0:
            samples_per_rir = [samples_per_rir] * (wav_samps // samples_per_rir)
        else:
            samples_per_rir = [samples_per_rir] * (wav_samps // samples_per_rir) + [wav_samps % samples_per_rir]
    (num_rirs, num_mics, rir_samps), rir_samps_t = traj_rirs.shape, traj_rirs_tar.shape[-1]
    assert num_rirs == len(samples_per_rir), "the number of rirs should match the length of samples_per_rir"

    rvbt = np.zeros((num_mics, rir_samps + wav_samps - 1), dtype=np.float32)
    target = np.zeros((num_mics, rir_samps_t + wav_samps - 1), dtype=np.float32)
    start_samp = 0
    for i, n_samps in enumerate(samples_per_rir):
        wav_i = wav[start_samp:start_samp + n_samps]
        rir_i = traj_rirs[i]
        rir_i_tar = traj_rirs_tar[i]
        rvbt[:, start_samp:start_samp + n_samps + rir_samps - 1] += fftconvolve(wav_i[np.newaxis], rir_i, mode='full', axes=-1)
        target[:, start_samp:start_samp + n_samps + rir_samps_t - 1] += fftconvolve(wav_i[np.newaxis], rir_i_tar, mode='full', axes=-1)
        start_samp += n_samps

    if align:
        rir = traj_rirs_tar[0, ref_channel, ...]
        delay = np.argmax(rir)
        rvbt = rvbt[:, delay:delay + wav.shape[-1]]
        target = target[:, delay:delay + wav.shape[-1]]
    return rvbt, target


def convolve_traj_with_win(wav: np.ndarray, traj_rirs: np.ndarray, samples_per_rir: int, wintype: str = 'trapezium20') -> np.ndarray:
    """Convolve wav by using a set of trajectory rirs (Note: the generated audio signal using this method barely have click noise)

    Args:
        wav: shape [T]
        traj_rirs: shape [num_rirs, num_mics, num_samples]
        samples_per_rir: the number of samples in wav for each trajectory rir
        wintype: hann, tri, or trapezium. by default, trapezium20 is used.

    Returns:
        np.ndarray: [num_mics, time]
    """
    assert wav.ndim == 1, "not implemented"
    wav_samps = wav.shape[0]

    hop = samples_per_rir
    samples_per_rir = samples_per_rir * 2
    num_rirs, num_mics, rir_samps = traj_rirs.shape

    if wintype == 'hann':
        win = np.hanning(samples_per_rir)
    elif wintype.startswith('trapezium'):  # 左右一边10个点
        n = int(wintype.replace('trapezium', ''))
        assert hop - n > 0, hop
        tri = np.arange(0, n) / (n - 1)
        tri2 = np.arange((n - 1), -1, -1) / (n - 1)
        zlen = (hop - n) // 2
        onelen = hop - n - zlen
        win = np.concatenate([np.zeros(zlen), tri, np.ones(onelen * 2), tri2, np.zeros(zlen)])
    else:
        assert wintype == 'tri', wintype
        win = np.concatenate([np.arange(0, samples_per_rir // 2), np.arange(samples_per_rir // 2 - 1, -1, -1)]) / (samples_per_rir // 2 - 1)

    out = np.zeros((num_mics, rir_samps + wav_samps - 1), dtype=np.float32)
    for i, start_samp in enumerate(range(0, wav_samps + hop - 1, hop)):
        rir_i = traj_rirs[i]

        if start_samp == 0:
            wav_i = wav[start_samp:start_samp + hop] * win[hop:]
            out[:, start_samp:start_samp + hop + rir_samps - 1] += fftconvolve(wav_i[np.newaxis], rir_i, axes=-1)
        elif wav.shape[-1] >= start_samp + hop:
            wav_i = wav[start_samp - hop:start_samp + hop] * win
            out[:, start_samp - hop:start_samp + hop + rir_samps - 1] += fftconvolve(wav_i[np.newaxis], rir_i, axes=-1)
        else:
            wav_i = wav[start_samp - hop:] * win[:wav.shape[-1] - start_samp + hop]
            out[:, start_samp - hop:] += fftconvolve(wav_i[np.newaxis], rir_i, axes=-1)

    return out


def align(rir: np.ndarray, rvbt: np.ndarray, target: np.ndarray, src: np.ndarray):
    assert rir.ndim == 1 and src.ndim == 1, (rir.shape, src.shape)
    delay = np.argmax(rir)
    rvbt = rvbt[:, delay:delay + src.shape[-1]]
    target = target[:, delay:delay + src.shape[-1]]
    return rvbt, target


def convolve1(wav: ndarray, rir: ndarray, ref_channel: Optional[int] = 0, align: bool = True) -> Union[Tuple[ndarray, ndarray], ndarray]:
    assert wav.ndim == 1, wav.shape
    while wav.ndim < rir.ndim:
        wav = wav[np.newaxis, ...]
    rvbt = fftconvolve(wav, rir, mode='full', axes=-1)
    if align:
        # Note: don't take the dry clean source as target if the ref_channel is not correct
        if rir.ndim >= 2:
            rir = rir[..., ref_channel, :]  # the second last dim is regarded as the channel dim
        delay = np.argmax(rir)
        rvbt = rvbt[..., delay:delay + wav.shape[-1]]
    return rvbt


def overlap2(rvbts: List[ndarray], targets: List[ndarray], ovlp_type: str, mix_frames: int, rng: Generator) -> Tuple[ndarray, ndarray]:
    assert np.array([rvbt_i.shape == target_i.shape for (rvbt_i, target_i) in zip(rvbts, targets)]).all(), "rvbt and target should have the same shape"
    assert len(rvbts) <= 2 and len(targets) <= 2, "this function is used only for two-speaker overlapping"
    assert rvbts[0].ndim == 2 and rvbts[0].shape[0] < rvbts[0].shape[1], "rvbt should have a shape of [chn, time]"

    num_spk, chn_num = len(rvbts), rvbts[0].shape[0]

    rvbt = np.zeros((num_spk, chn_num, mix_frames), dtype=np.float32)
    target = np.zeros((num_spk, chn_num, mix_frames), dtype=np.float32)

    for i, (rvbt_i, target_i) in enumerate(zip(rvbts, targets)):
        # overlap signals
        Ti = rvbt_i.shape[-1]  # use all revbt signals

        if ovlp_type == 'full':
            shift = 0
        elif ovlp_type == 'mid':
            if Ti == mix_frames:
                shift = 0
            else:
                shift = rng.integers(low=0, high=mix_frames - Ti + 1)  # [0, mix_frames - use_len]
        elif ovlp_type == 'start' or ovlp_type == 'end':
            assert num_spk == 2
            if Ti == mix_frames:
                shift = 0
            else:
                shift = {'start': 0, 'end': mix_frames - Ti}[ovlp_type]
        else:
            assert ovlp_type == 'headtail', ovlp_type
            assert num_spk == 2
            shift = 0 if i == 0 else (mix_frames - Ti)

        rvbt[i, :, shift:shift + Ti] = rvbt_i[:, :]
        target[i, :, shift:shift + Ti] = target_i[:, :]
    return rvbt, target


def overlap3(rvbts: List[ndarray], targets: List[ndarray], mix_frames: int, rng: Generator, output_stream: int = 2) -> Tuple[ndarray, ndarray]:
    assert np.array([rvbt_i.shape == target_i.shape for (rvbt_i, target_i) in zip(rvbts, targets)]).all(), "rvbt and target should have the same shape"
    assert len(rvbts) == 3 and len(targets) == 3, "this function is used only for 3-speaker overlapping"
    assert output_stream == 2, "2-stream output is supported only"
    assert rvbts[0].ndim == 2 and rvbts[0].shape[0] < rvbts[0].shape[1], "rvbt should have a shape of [chn, time]"

    num_spk, chn_num = len(rvbts), rvbts[0].shape[0]

    rvbt = np.zeros((2, chn_num, mix_frames), dtype=np.float32)
    target = np.zeros((2, chn_num, mix_frames), dtype=np.float32)

    rvbt[0, :, :] = rvbts[0][:, :]
    rvbt[1, :, :rvbts[1].shape[-1]] = rvbts[1][:, :]
    rvbt[1, :, -rvbts[2].shape[-1]:] = rvbts[2][:, :]

    target[0, :, :] = targets[0][:, :]
    target[1, :, :targets[1].shape[-1]] = targets[1][:, :]
    target[1, :, -targets[2].shape[-1]:] = targets[2][:, :]

    return rvbt, target


def cal_coeff_for_adjusting_relative_energy(wav1: ndarray, wav2: ndarray, target_dB: float) -> Optional[float]:
    r"""calculate the coefficient used for adjusting the relative energy of two signals

    Args:
        wav1: the first wav
        wav2: the second wav
        target_dB: the target relative energy in dB, i.e. after adjusting: 10 * log_10 (average_energy(wav1) / average_energy(wav2 * coeff)) = target_dB

    Returns:
        float: coeff
    """
    # compute averaged energy over time and channel
    ae1 = np.sum(wav1**2) / np.prod(wav1.shape)
    ae2 = np.sum(wav2**2) / np.prod(wav2.shape)
    if ae1 == 0 or ae2 == 0 or not np.isfinite(ae1) or not np.isfinite(ae2):
        return None
    # compute the coefficients
    coeff = np.sqrt(ae1 / ae2 * np.power(10, -target_dB / 10))
    return coeff  # multiply it with wav2
